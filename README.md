# Video Audit AI â€“ Enterprise Compliance Audit Platform

Video Audit AI is an intelligent, endâ€‘toâ€‘end platform that automatically audits video content (e.g., YouTube videos) against brand safety and regulatory rules. It combines Azure AI services, a vector knowledge base, and a LangGraphâ€‘powered workflow to detect compliance violations in spoken and onâ€‘screen content.

---

## âœ¨ Features

- **YouTube ingestion** â€“ Downloads videos using `ytâ€‘dlp` and uploads them to Azure Video Indexer.
- **Multimodal extraction** â€“ Extracts speechâ€‘toâ€‘text transcripts and onâ€‘screen text (OCR) via Video Indexer.
- **Retrievalâ€‘Augmented Generation (RAG)** â€“ Queries a vectorized knowledge base of brand rules (stored in Azure AI Search) to retrieve relevant guidelines.
- **LLMâ€‘powered auditing** â€“ Uses Azure OpenAI (GPTâ€‘4) to analyse content against retrieved rules and return structured compliance results.
- **REST API** â€“ FastAPI server with autoâ€‘generated documentation (`/docs`).
- **Observability** â€“ Integrated with Azure Monitor (Application Insights) for metrics, logs, and traces; LangSmith for LLM tracing.
- **Modular, graphâ€‘based workflow** â€“ Built with LangGraph, making it easy to extend (e.g., add humanâ€‘inâ€‘theâ€‘loop steps).

---

## ğŸ§± Architecture Overview

## Architecture

![Video Audit AI Architecture](assets/videoauditaiarchitecture.png)



The system is composed of three main layers:

### 1. **Ingestion & Indexing** (oneâ€‘time setup)
- **Knowledge Base Builder** â€“ `index_documents.py` reads PDF rulebooks, splits them into chunks, generates embeddings (Azure OpenAI `textâ€‘embeddingâ€‘3â€‘small`), and stores them in an **Azure AI Search** index.

### 2. **Orchestration Layer** (LangGraph workflow)
- **State** â€“ A shared `VideoAuditState` object carries data through the workflow (video URL, transcript, OCR, compliance results, errors, etc.).
- **Nodes**:
  - **Indexer Node** â€“ Downloads a YouTube video, uploads to Azure Video Indexer, waits for processing, and extracts transcript + OCR.
  - **Auditor Node** â€“ Performs RAG:  
    1. Combines transcript + OCR into a query.  
    2. Retrieves topâ€‘k relevant rule chunks from Azure AI Search.  
    3. Calls Azure OpenAI (GPTâ€‘4) with a strict JSON prompt to identify violations.  
    4. Parses and returns results.

### 3. **Serving Layer** (API / CLI)
- **CLI** â€“ `main.py` simulates a full audit from the command line.
- **REST API** â€“ `server.py` exposes a POST `/audit` endpoint, uses the same compiled graph, and returns a structured `AuditResponse`.

All telemetry is automatically collected by **Azure Monitor** (via OpenTelemetry) and **LangSmith**.

---

## ğŸ“‹ Prerequisites

- An **Azure subscription** with permissions to create resources.
- Python 3.10+ and `uv` (or `pip`).
- (Optional) A **LangSmith** account for LLM tracing.

---

## ğŸ”§ Setting Up Azure Resources & API Keys

Follow these steps to provision all required Azure services and obtain the necessary credentials. After creation, youâ€™ll populate the `.env` file.

### 1. Azure OpenAI
- Create an **Azure OpenAI** resource in the [Azure Portal](https://portal.azure.com).
- Deploy two models:
  - **Chat model** â€“ e.g., `gpt-4o` (deployment name: `gpt-4o`).
  - **Embeddings model** â€“ `textâ€‘embeddingâ€‘3â€‘small` (deployment name: `textâ€‘embeddingâ€‘3â€‘small`).
- After deployment, note:
  - **Endpoint** â€“ `https://<your-resource-name>.openai.azure.com/`
  - **API key** â€“ from "Keys and Endpoint" blade.

### 2. Azure AI Search
- Create an **Azure AI Search** resource (any tier, but Basic or higher recommended for vectors).
- Under "Settings" > "Keys", copy the **primary admin key**.
- Note the **endpoint** â€“ `https://<your-service-name>.search.windows.net`.

### 3. Azure Video Indexer
- Create a **Video Indexer** account (classic or ARMâ€‘based).  
  > *Note:* If you use the ARM version, you also need the subscription ID and resource group.
- In the Video Indexer portal (or via ARM), note:
  - **Account ID** â€“ can be found in the account settings.
  - **Location** â€“ e.g., `eastus`.
  - If using ARM, also note:
    - **Subscription ID**
    - **Resource Group** name
    - **Resource name** (the name you gave the Video Indexer account)

### 4. Azure Storage (optional, for future extensions)
- Create a **Storage Account** (general purpose v2).
- Under "Access keys", copy a **connection string**. (Currently unused but kept for future expansion.)

### 5. Application Insights (Telemetry)
- In the Azure Portal, create an **Application Insights** resource.
- Copy the **instrumentation key** (or the full connection string) from the "Overview" blade.

### 6. LangSmith (LLM Tracing)
- Sign up at [smith.langchain.com](https://smith.langchain.com).
- Create a project (e.g., `video-audit-ai`).
- Generate an **API key** in the settings page.

---

## âš™ï¸ Environment Configuration

1. Clone the repository:
   ```bash
   git clone https://github.com/duyilemi/video_audit_ai.git
   cd video_audit_ai
   ```

2. Create a `.env` file in the project root and fill in all values using the template below:

   ```env
   # Azure Storage (optional)
   AZURE_STORAGE_CONNECTION_STRING="your-storage-connection-string"

   # Azure OpenAI
   AZURE_OPENAI_API_KEY="your-openai-key"
   AZURE_OPENAI_ENDPOINT="https://<your-resource>.openai.azure.com/"
   AZURE_OPENAI_API_VERSION="2024-12-01-preview"
   AZURE_OPENAI_CHAT_DEPLOYMENT="gpt-4o"
   AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-small"

   # Azure AI Search
   AZURE_SEARCH_ENDPOINT="https://<your-search>.search.windows.net"
   AZURE_SEARCH_API_KEY="your-search-admin-key"
   AZURE_SEARCH_INDEX_NAME="brand-compliance-rules"

   # Azure Video Indexer
   AZURE_VI_NAME="brand-yt-project-001"                # Your VI account name
   AZURE_VI_LOCATION="eastus"                           # e.g., eastus
   AZURE_VI_ACCOUNT_ID="your-vi-account-id"
   AZURE_SUBSCRIPTION_ID="your-azure-subscription-id"   # For ARM auth
   AZURE_RESOURCE_GROUP="your-resource-group"

   # Application Insights
   APPLICATIONINSIGHTS_CONNECTION_STRING="InstrumentationKey=xxx;IngestionEndpoint=..."

   # LangSmith
   LANGCHAIN_TRACING_V2=true
   LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
   LANGCHAIN_API_KEY="your-langsmith-key"
   LANGCHAIN_PROJECT="brand-guardian-prod"
   ```

---

## ğŸš€ Running the Project

### Install dependencies
We recommend using `uv` for fast dependency management:
```bash
uv venv

uv add -r requirements.txt
```

### 1. Index the knowledge base (oneâ€‘time)
Place your brand rule PDFs in `backend/data/` and run:
```bash
uv run python backend/scripts/index_documents.py
```
This will chunk the PDFs, generate embeddings, and upload them to your Azure AI Search index.

### 2. Test with the CLI
```bash
uv run python main.py
```
You should see the workflow execute and print a compliance report.

### 3. Start the API server
```bash
uv run uvicorn backend.src.api.server:app --reload
```
- Interactive API docs: [http://localhost:8000/docs](http://localhost:8000/docs)
- Health check: [http://localhost:8000/health](http://localhost:8000/health)
- POST `/audit` with a JSON body:
  ```json
  { "video_url": "https://youtu.be/..." }
  ```

---

## ğŸ“ˆ Production Improvements

While the current implementation demonstrates the core concepts, an enterpriseâ€‘grade deployment would require additional considerations:

### ğŸ”’ Security & Compliance
- **Managed Identity** â€“ Replace API keys with Azure Managed Identities for all Azure services (no secrets in `.env`).
- **Secrets Management** â€“ Use Azure Key Vault to store and rotate secrets.
- **Network Isolation** â€“ Place all Azure resources inside a VNet, with private endpoints where possible.
- **Data Residency** â€“ Ensure all services are deployed in the required geographic region.

### âš¡ Scalability & Performance
- **Async Processing** â€“ Use `ainvoke()` with `asyncio` to handle multiple concurrent audits without blocking.
- **Queueâ€‘Based Ingestion** â€“ Offload video processing to Azure Queue Storage or Service Bus; have a separate worker process polling for new jobs.
- **Caching** â€“ Cache frequently retrieved rule chunks in Redis (Azure Cache for Redis) to reduce search latency.
- **Autoâ€‘scaling** â€“ Configure the API server (e.g., on Azure Container Apps or AKS) to scale based on request load.

### ğŸ›¡ï¸ Reliability & Error Handling
- **Retry Policies** â€“ Implement exponential backoff for transient failures (Azure OpenAI rate limits, Search throttling).
- **Dead Letter Queue** â€“ For videos that repeatedly fail processing, send them to a deadâ€‘letter queue for manual inspection.
- **Graceful Degradation** â€“ If the LLM is unavailable, return a meaningful error instead of crashing.

### ğŸ” Observability & Monitoring
- **Custom Metrics** â€“ Track audit duration, number of violations per category, video processing time, etc., and send to Azure Monitor.
- **Alerting** â€“ Set up alerts for high error rates, long processing times, or quota exhaustion.
- **Distributed Tracing** â€“ Already enabled via OpenTelemetry; ensure all Azure SDK calls are properly instrumented.

### ğŸ’¡ Feature Enhancements
- **Multiâ€‘Language Support** â€“ Video Indexer can transcribe many languages; extend the audit to support them.
- **Humanâ€‘inâ€‘theâ€‘Loop** â€“ For borderline cases, route the audit to a human reviewer (using Azure Logic Apps or a custom approval workflow).
- **Custom Rules Engine** â€“ Allow nonâ€‘technical users to define new rules via a UI, which are then embedded and stored in the knowledge base.
- **Batch Auditing** â€“ Support auditing of multiple videos in one request, returning a consolidated report.

---

## ğŸ“ Project Structure

```
video-audit-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/                   # PDF rulebooks (for indexing)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ index_documents.py   # Builds vector knowledge base
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ server.py        # FastAPI server
â”‚       â”‚   â””â”€â”€ telemetry.py     # Azure Monitor setup
â”‚       â”œâ”€â”€ graph/
â”‚       â”‚   â”œâ”€â”€ nodes.py         # LangGraph nodes
â”‚       â”‚   â”œâ”€â”€ state.py         # Typed state schema
â”‚       â”‚   â””â”€â”€ workflow.py      # Graph assembly
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ video_indexer.py # Azure Video Indexer wrapper
â”œâ”€â”€ main.py                      # CLI simulation entry point
â”œâ”€â”€ .env                          # Environment variables (not committed)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributing

We welcome contributions! Please open an issue or submit a pull request. Ensure you follow the existing code style and include tests where applicable.

---

## ğŸ“„ License

This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

Built with [LangChain](https://langchain.com/), [LangGraph](https://langchain-ai.github.io/langgraph/), [FastAPI](https://fastapi.tiangolo.com/), and Microsoft Azure.